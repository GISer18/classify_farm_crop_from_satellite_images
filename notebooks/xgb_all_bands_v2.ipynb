{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import  XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, log_loss, f1_score, accuracy_score, make_scorer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras import optimizers, callbacks \n",
    "\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils, plot_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "import collections\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (2494, 6094)\n",
      "test shape (1074, 6093)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('stats/train_final.csv')\n",
    "test = pd.read_csv('stats/test_final.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "print('train shape {}'.format(train.shape))\n",
    "print('test shape {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train['Crop_Id_Ne']),\n",
    "                                                 train['Crop_Id_Ne'])\n",
    "class_weights = list(class_weights)\n",
    "\n",
    "# y_train= pd.get_dummies(train['Crop_Id_Ne'])\n",
    "y_train = train['Crop_Id_Ne']\n",
    "\n",
    "X_train = train.drop(['Field_Id','Crop_Id_Ne', 'Subregion'], axis = 1)\n",
    "X_train.reset_index(inplace = True, drop= True)\n",
    "X_test = test.drop(['Field_Id', 'Subregion'], axis = 1)\n",
    "X_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use only the bands mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "dates = [\"2017-01-01\", \"2017-01-31\", \"2017-02-10\", \"2017-03-12\", \"2017-03-22\", \"2017-05-31\", \"2017-06-20\", \n",
    "        \"2017-07-10\", \"2017-07-15\", \"2017-08-04\", \"2017-08-19\"]\n",
    "\n",
    "features = ['red', 'green', 'blue', 'band5', 'band6', 'band7', 'nir', 'band8a', 'band11', 'band12',\n",
    "           'ndvi', 'reip', 'datt3', 'gemi', 'msbi', 'ccci', 'avi', 'cvi', 'ndsi', 'siwsi', 'savi', 'evi', 'ndre']\n",
    "\n",
    "mean_columns = []\n",
    "for date in dates:\n",
    "    for layer in features:\n",
    "        mean_columns.append(layer + '_mean'+date)\n",
    "print(len(mean_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[mean_columns]\n",
    "X_test = test[mean_columns]\n",
    "y_train = train['Crop_Id_Ne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 3\n",
      "accuracy_score 0.8011976047904191\n",
      "log loss is :  0.6621332448946234\n",
      "f1 score  0.7786787266070815\n",
      "[[ 38   0   0   4   2   0   0   4   0]\n",
      " [  0   0   0   0   0   1   1   1   0]\n",
      " [  1   0   7   9   1   0   9   5   0]\n",
      " [  0   0   0 163   0   2   7   7   0]\n",
      " [  1   0   0   2  87   1   2   2   0]\n",
      " [  0   0   0   2   1  26  11   9   0]\n",
      " [  0   0   6   8   3   4  56  12   0]\n",
      " [  2   0   1   6   2   3   8 292   0]\n",
      " [  0   0   0   0   1   0   0  25   0]]\n",
      "\n",
      "2 of kfold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8149038461538461\n",
      "log loss is :  0.6343234068651957\n",
      "f1 score  0.791669857109646\n",
      "[[ 39   0   0   0   1   1   4   2   0]\n",
      " [  0   0   1   0   0   0   0   1   0]\n",
      " [  0   0   7   6   1   0   5  13   0]\n",
      " [  1   0   1 158   1   0  11   7   0]\n",
      " [  0   0   0   0  84   1   4   5   0]\n",
      " [  0   0   0   5   1  23   5  15   0]\n",
      " [  0   0   2   4   3   4  62  14   0]\n",
      " [  0   0   0   2   2   2   1 305   2]\n",
      " [  0   0   0   2   0   0   0  24   0]]\n",
      "\n",
      "3 of kfold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.7980652962515115\n",
      "log loss is :  0.6710893983547007\n",
      "f1 score  0.7763822868177324\n",
      "[[ 39   0   1   1   0   2   0   4   0]\n",
      " [  0   0   0   0   0   0   0   2   0]\n",
      " [  0   0   8   8   0   0   6   9   0]\n",
      " [  0   0   1 164   0   3   3   7   0]\n",
      " [  3   0   0   0  82   0   7   2   0]\n",
      " [  1   0   0   4   0  18  12  13   0]\n",
      " [  1   0   5  15   3   1  53  11   0]\n",
      " [  1   0   1   3   2   3   7 295   1]\n",
      " [  0   0   0   0   0   0   2  22   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "kf = StratifiedKFold(n_splits=3,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(X_train,y_train):\n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]\n",
    "    ytr,yvl = y_train[train_index],y_train[test_index]\n",
    "    \n",
    "    model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "         gamma=0.0, max_delta_step=0.0, min_child_weight=1.0,\n",
    "         missing=None, n_jobs=-1, objective='multi:softprob', random_state=42, reg_alpha=0.0,\n",
    "         reg_lambda=1.0, scale_pos_weight=1.0, tree_method='auto', num_class = 9, silent=False)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred=model.predict(xvl)\n",
    "    pred_prob = model.predict_proba(xvl) \n",
    "    print('accuracy_score',accuracy_score(yvl,pred))\n",
    "    print('log loss is : ', log_loss(yvl, pred_prob))\n",
    "    print('f1 score ', f1_score(yvl, pred, average='weighted'))\n",
    "    print(confusion_matrix(yvl,pred))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use grid search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbcl = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "         gamma=0.0, max_delta_step=0.0, min_child_weight=1.0,\n",
    "         missing=None, n_jobs=-1, objective='multi:softprob', random_state=42, reg_alpha=0.0,\n",
    "         reg_lambda=1.0, scale_pos_weight=1.0, tree_method='auto', num_class = 9, silent=False)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# param_grid = { \n",
    "#     'colsample_bytree':[.75,1],\n",
    "#     'learning_rate':[0.01,0.05,0.1,0.3,0.5],\n",
    "#     'max_depth':[1,2,3,5,10, 20, 50, 100],\n",
    "#     'subsample':[.75,1],\n",
    "#     'n_estimators': list(range(50, 1000, 50))\n",
    "# }\n",
    "\n",
    "param_grid = { \n",
    "    'colsample_bytree':[.75,1],\n",
    "    'learning_rate':[0.01,0.1,0.5],\n",
    "    'max_depth':[1,50],\n",
    "    'subsample':[.75,1],\n",
    "    'n_estimators': list(range(50, 100, 50))\n",
    "}\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "grid_search = GridSearchCV(estimator=xgbcl, scoring=LogLoss, param_grid=param_grid, n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set our final hyperparameters to the tuned values\n",
    "xgbcl = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "         gamma=0.0, max_delta_step=0.0, min_child_weight=1.0,\n",
    "         missing=None, n_jobs=-1, objective='multi:softprob', random_state=42, reg_alpha=0.0,\n",
    "         reg_lambda=1.0, scale_pos_weight=1.0, tree_method='auto', num_class = 9, silent=False,\n",
    "         colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "         learning_rate = grid_result.best_params_['learning_rate'], \n",
    "         max_depth = grid_result.best_params_['max_depth'], \n",
    "         subsample = grid_result.best_params_['subsample'], \n",
    "         n_estimators = grid_result.best_params_['n_estimators'])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(estimator=xgbcl, X=X_train, y=y_train, cv=kfold, n_jobs=-1, \n",
    "                        scoring=['accuracy', 'roc_auc', 'precision', 'recall', 'f1'])\n",
    "\n",
    "print('Training 5-fold Cross Validation Results:\\n')\n",
    "print('AUC: ', scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
